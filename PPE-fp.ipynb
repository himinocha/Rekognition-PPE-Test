{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df98db7d",
   "metadata": {},
   "source": [
    "# AWS Rekognition PPE\n",
    "## Jeremy Montgomery, Se Eun Kim, Isaac Cha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f97b1",
   "metadata": {},
   "source": [
    "### Step 1. Import and Initialize necessary resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419f7fe",
   "metadata": {},
   "source": [
    "We will use `boto3` library to use AWS services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a385df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388a0773",
   "metadata": {},
   "source": [
    "We first initialize AWS Rekognition service using `boto3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3fc672",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a75c2",
   "metadata": {},
   "source": [
    "Then we access our S3 bucket named `qtm350-fp` where our image data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bdfc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Bucket.objectsCollection(s3.Bucket(name='qtm350-fp'), s3.ObjectSummary)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_resource = boto3.resource('s3')\n",
    "my_bucket = s3_resource.Bucket('qtm350-fp')\n",
    "summaries = my_bucket.objects.all()\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d40c876",
   "metadata": {},
   "source": [
    "We then extract the names of the image in our S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8090b7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of images in our S3 bucket: 104\n",
      "List of image names:\n",
      " ['image-asset/1684177591-huge.jpg', 'image-asset/abdul-zreika-pMzlO7xJAd4-unsplash.jpg', 'image-asset/ahsanization-wpvEMgFV4w0-unsplash.jpg', 'image-asset/albany-capture-7o4t241DizQ-unsplash.jpg', 'image-asset/baptiste-pCH5-U4IBZU-unsplash.jpg', 'image-asset/bianca-sbircea-constantin-I-p1wEjKOTk-unsplash.jpg', 'image-asset/clem-onojeghuo-zZza888FSKg-unsplash.jpg', 'image-asset/dean-bennett-aBV8pVODWiM-unsplash.jpg', 'image-asset/emma-houghton-EixJzIdl4bc-unsplash.jpg', 'image-asset/emmanuel-ikwuegbu-KHO_jvns5Xc-unsplash.jpg', 'image-asset/emmanuel-ikwuegbu-zWOgsj3j0wA-unsplash.jpg', 'image-asset/eric-wang-umD2Bj4FmMU-unsplash.jpg', 'image-asset/gordianus-ernesto-ogTklVn1vpQ-unsplash.jpg', 'image-asset/irma-yanti-FC1RUP273r8-unsplash.jpg', 'image-asset/istrfry-marcus-pjW5WezrdJk-unsplash.jpg', 'image-asset/james-kovin-qqLxF3M-MA8-unsplash.jpg', 'image-asset/jeriden-villegas-VLPUm5wP5Z0-unsplash.jpg', 'image-asset/jeriden-villegas-niSnhfMjiMI-unsplash.jpg', 'image-asset/joe-holland-80zZ1s24Nag-unsplash.jpg', 'image-asset/josh-olalde-X1P1_EDNnok-unsplash.jpg', 'image-asset/josue-isai-ramos-figueroa-qvBYnMuNJ9A-unsplash.jpg', 'image-asset/kai-pilger-RQdMhdDN5ZU-unsplash.jpg', 'image-asset/kentaro-toma-jCKC5W8s-cc-unsplash.jpg', 'image-asset/kevin-grieve-QCdRhVj7N8w-unsplash.jpg', 'image-asset/mads-eneqvist-J9jYy9S1zAk-unsplash.jpg', 'image-asset/max-larochelle-QzP1GcDOSC8-unsplash.jpg', 'image-asset/mitchell-luo-TtX79Vkm8gs-unsplash.jpg', 'image-asset/mitchell-luo-YhoXp0AdEWc-unsplash.jpg', 'image-asset/morgan-von-gunten-G-YbAOA6qqQ-unsplash.jpg', 'image-asset/mufid-majnun-EiVEsCCLHFE-unsplash.jpg', 'image-asset/mufid-majnun-ji0wcfoW7Zc-unsplash.jpg', 'image-asset/ricardo-gomez-angel-sYK-jN0sKBY-unsplash.jpg', 'image-asset/rossella-porta-vPBxg4cpU4Y-unsplash.jpg', 'image-asset/sams-solutions-qsk_ifUucWE-unsplash.jpg', 'image-asset/scott-blake-bKGpAV4gFnc-unsplash.jpg', 'image-asset/scott-blake-keHNwiEsJQs-unsplash.jpg', 'image-asset/scott-blake-wq7oyx_Kx-4-unsplash.jpg', 'image-asset/scott-blake-x-ghf9LjrVg-unsplash.jpg', 'image-asset/shutterstock_1682171860.jpg', 'image-asset/shutterstock_1700509294.jpg', 'image-asset/shutterstock_1711476070.jpg', 'image-asset/shutterstock_1713505240.jpg', 'image-asset/shutterstock_1801645951.jpg', 'image-asset/shutterstock_1821026021.jpg', 'image-asset/shutterstock_1930255157.jpg', 'image-asset/shutterstock_1933514846.jpg', 'image-asset/shutterstock_401721562.jpg', 'image-asset/silvia-brazzoduro-YSxcf6C_SEg-unsplash.jpg', 'image-asset/spencer-davis-QTKwYmMumfk-unsplash.jpg', 'image-asset/spencer-davis-gJsBR0CYpA4-unsplash.jpg', 'image-asset/taken/IMG_8029.JPG', 'image-asset/taken/IMG_8030.JPG', 'image-asset/taken/IMG_8031.JPG', 'image-asset/taken/IMG_8032.JPG', 'image-asset/taken/IMG_8033.JPG', 'image-asset/taken/IMG_8034.JPG', 'image-asset/taken/IMG_8035.JPG', 'image-asset/taken/IMG_8036.JPG', 'image-asset/taken/IMG_8037.JPG', 'image-asset/taken/IMG_8038.JPG', 'image-asset/taken/IMG_8039.JPG', 'image-asset/taken/IMG_8040.JPG', 'image-asset/taken/IMG_8041.JPG', 'image-asset/taken/IMG_8042.JPG', 'image-asset/taken/IMG_8043.JPG', 'image-asset/taken/IMG_8044.JPG', 'image-asset/taken/IMG_8045.JPG', 'image-asset/taken/IMG_8046.JPG', 'image-asset/taken/IMG_8047.JPG', 'image-asset/taken/IMG_8048.JPG', 'image-asset/taken/IMG_8049.JPG', 'image-asset/taken/IMG_8050.JPG', 'image-asset/taken/IMG_8051.JPG', 'image-asset/taken/IMG_8052.JPG', 'image-asset/taken/IMG_8053.JPG', 'image-asset/taken/IMG_8054.JPG', 'image-asset/taken/IMG_8055.JPG', 'image-asset/taken/IMG_8056.JPG', 'image-asset/taken/IMG_8057.JPG', 'image-asset/taken/IMG_8058.JPG', 'image-asset/taken/IMG_8059.JPG', 'image-asset/taken/IMG_8060.JPG', 'image-asset/taken/IMG_8061.JPG', 'image-asset/taken/IMG_8062.JPG', 'image-asset/taken/IMG_8063.JPG', 'image-asset/taken/IMG_8064.JPG', 'image-asset/taken/IMG_8065.JPG', 'image-asset/taken/IMG_8066.JPG', 'image-asset/taken/IMG_8067.JPG', 'image-asset/taken/IMG_8068.JPG', 'image-asset/taken/IMG_8069.JPG', 'image-asset/taken/IMG_8070.JPG', 'image-asset/taken/IMG_8071.JPG', 'image-asset/taken/IMG_8072.JPG', 'image-asset/taken/IMG_8073.JPG', 'image-asset/taken/IMG_8074.JPG', 'image-asset/thisisengineering-raeng-0LnH9j9Wirw-unsplash.jpg', 'image-asset/thisisengineering-raeng-CUA-_IGpXXo-unsplash.jpg', 'image-asset/thisisengineering-raeng-EhPSMCvT9rY-unsplash.jpg', 'image-asset/thisisengineering-raeng-gDjNWuW3gJw-unsplash.jpg', 'image-asset/thisisengineering-raeng-vEoMKBdUIzs-unsplash.jpg', 'image-asset/vitolda-klein-lAqSzwr5eQc-unsplash.jpg', 'image-asset/vladyslav-melnyk-vyL-v8DuZuY-unsplash.jpg', 'image-asset/xinqi-yao-9f5M0KTl6Uc-unsplash.jpg']\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "for image in summaries:\n",
    "    if ((image.key.startswith('image-asset/taken') and image.key.endswith('.JPG')) or (image.key.endswith('.jpg'))):\n",
    "        images.append(image.key)\n",
    "print(f'Total Number of images in our S3 bucket: {len(images)}')\n",
    "print(f'List of image names:\\n {images}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786c159",
   "metadata": {},
   "source": [
    "Here is one example image from `images`.\\\n",
    "All of our images has public access.\\\n",
    "And this following image can be access with this link: [Picture of Jeremy M.](https://qtm350-fp.s3.amazonaws.com/image-asset/taken/IMG_8038.JPG).\n",
    "<img src=\"https://qtm350-fp.s3.amazonaws.com/image-asset/taken/IMG_8038.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c3f3a",
   "metadata": {},
   "source": [
    "### Step 2. Test function with test image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc356fa5",
   "metadata": {},
   "source": [
    "We will now test `.detect_protective_equipment()` from Rekognition with this example image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1502af43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://qtm350-fp.s3.amazonaws.com/image-asset/taken/IMG_8038.JPG\n"
     ]
    }
   ],
   "source": [
    "test = images[59]\n",
    "print(f'https://qtm350-fp.s3.amazonaws.com/{images[59]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fad7fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppe_response = client.detect_protective_equipment(Image={'S3Object':{'Bucket':\"qtm350-fp\",'Name':f\"{test}\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bf457c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(ppe_response['Persons']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06c0ff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProtectiveEquipmentModelVersion': '1.0',\n",
       " 'Persons': [{'BodyParts': [{'Name': 'FACE',\n",
       "     'Confidence': 98.63581085205078,\n",
       "     'EquipmentDetections': [{'BoundingBox': {'Width': 0.04409034177660942,\n",
       "        'Height': 0.05509009212255478,\n",
       "        'Left': 0.4701075255870819,\n",
       "        'Top': 0.5598670244216919},\n",
       "       'Confidence': 99.9937515258789,\n",
       "       'Type': 'FACE_COVER',\n",
       "       'CoversBodyPart': {'Confidence': 72.3757095336914, 'Value': True}}]},\n",
       "    {'Name': 'LEFT_HAND',\n",
       "     'Confidence': 98.03620910644531,\n",
       "     'EquipmentDetections': []},\n",
       "    {'Name': 'RIGHT_HAND',\n",
       "     'Confidence': 97.59645080566406,\n",
       "     'EquipmentDetections': []},\n",
       "    {'Name': 'HEAD',\n",
       "     'Confidence': 99.91152954101562,\n",
       "     'EquipmentDetections': []}],\n",
       "   'BoundingBox': {'Width': 0.18333333730697632,\n",
       "    'Height': 0.512499988079071,\n",
       "    'Left': 0.4020833373069763,\n",
       "    'Top': 0.48515623807907104},\n",
       "   'Confidence': 99.94629669189453,\n",
       "   'Id': 0}],\n",
       " 'ResponseMetadata': {'RequestId': '13418f91-59e7-4cca-93b8-93974862ad03',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '13418f91-59e7-4cca-93b8-93974862ad03',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '766',\n",
       "   'date': 'Sun, 21 Nov 2021 02:14:06 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppe_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eeeb1d",
   "metadata": {},
   "source": [
    "We can see from `ppe_response` that `.detect_protective_equipment()` returns the number of people inside the photo, as well as the labeling of the specific parts of the body where PPE can be worn and respective confidence scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10463b6c",
   "metadata": {},
   "source": [
    "### Step 3. Execute `detect_protective_equipment()` on every image, extract necessary data, and store it as .csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99bedc",
   "metadata": {},
   "source": [
    "We first import `pandas`, in which we will use `DataFrame` to store our data and finally export it to .csv using `to_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "589ed82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb20f4",
   "metadata": {},
   "source": [
    "We create an empty dataframe with columns for values we want to store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac29b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img','bodyPartName', 'bodyPartConf', 'eq_type', 'eq_conf', 'eqCover_conf', 'eq_box', 'eqCover_bool'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490edaf",
   "metadata": {},
   "source": [
    "We run a for loop for each image in our `images` list, extracting and storing the fields we need to our dataframe `df`.\\\n",
    "In addition, we multiply `Width` and `Height` of `BoundingBox` to store the area of `BoundingBox` to `df['eq_box']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0092907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_count = 0\n",
    "for image in images:\n",
    "    try:\n",
    "        output = client.detect_protective_equipment(Image={'S3Object':{'Bucket':\"qtm350-fp\",'Name':f\"{image}\"}})\n",
    "        persons = output['Persons']\n",
    "        for person in persons:\n",
    "            bodyParts= person['BodyParts']\n",
    "            for bodypart in bodyParts:\n",
    "                name = bodypart['Name']\n",
    "                conf = bodypart['Confidence']\n",
    "                equipmentDetection = bodypart['EquipmentDetections']\n",
    "                if (len(equipmentDetection)==0):\n",
    "                    continue\n",
    "                else:\n",
    "                    for eq in equipmentDetection:\n",
    "                        eq_conf = eq['Confidence']\n",
    "                        eq_type = eq['Type']\n",
    "                        eqCover_conf = eq['CoversBodyPart']['Confidence']\n",
    "                        eq_box = eq['BoundingBox']['Width']*eq['BoundingBox']['Height']\n",
    "                        eqCover_bool = eq['CoversBodyPart']['Value']\n",
    "\n",
    "                        df = df.append({\n",
    "                                        'img':image,\n",
    "                                        'bodyPartName':name,\n",
    "                                        'bodyPartConf':conf,\n",
    "                                        'eq_type':eq_type,\n",
    "                                        'eq_conf':eq_conf,\n",
    "                                        'eqCover_conf':eqCover_conf,\n",
    "                                        'eq_box':eq_box,\n",
    "                                        'eqCover_bool':eqCover_bool,\n",
    "                                       }, ignore_index=True)\n",
    "    except Exception: # exception case for image type errors\n",
    "        err_count = err_count+1\n",
    "        #print(\"error\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747aaf14",
   "metadata": {},
   "source": [
    "Here is the output `df` from the for loop above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc7f0b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>bodyPartName</th>\n",
       "      <th>bodyPartConf</th>\n",
       "      <th>eq_type</th>\n",
       "      <th>eq_conf</th>\n",
       "      <th>eqCover_conf</th>\n",
       "      <th>eq_box</th>\n",
       "      <th>eqCover_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image-asset/1684177591-huge.jpg</td>\n",
       "      <td>FACE</td>\n",
       "      <td>99.458809</td>\n",
       "      <td>FACE_COVER</td>\n",
       "      <td>99.934128</td>\n",
       "      <td>90.723564</td>\n",
       "      <td>0.019554</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image-asset/1684177591-huge.jpg</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>99.969254</td>\n",
       "      <td>HEAD_COVER</td>\n",
       "      <td>68.631821</td>\n",
       "      <td>95.665405</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image-asset/1684177591-huge.jpg</td>\n",
       "      <td>FACE</td>\n",
       "      <td>96.018814</td>\n",
       "      <td>FACE_COVER</td>\n",
       "      <td>99.720436</td>\n",
       "      <td>89.325356</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image-asset/1684177591-huge.jpg</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>99.608627</td>\n",
       "      <td>HEAD_COVER</td>\n",
       "      <td>95.798180</td>\n",
       "      <td>98.066414</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image-asset/1684177591-huge.jpg</td>\n",
       "      <td>FACE</td>\n",
       "      <td>94.266830</td>\n",
       "      <td>FACE_COVER</td>\n",
       "      <td>99.801407</td>\n",
       "      <td>96.197754</td>\n",
       "      <td>0.010404</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>image-asset/taken/IMG_8072.JPG</td>\n",
       "      <td>FACE</td>\n",
       "      <td>99.981300</td>\n",
       "      <td>FACE_COVER</td>\n",
       "      <td>95.747658</td>\n",
       "      <td>99.999992</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>image-asset/taken/IMG_8073.JPG</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>92.567757</td>\n",
       "      <td>HEAD_COVER</td>\n",
       "      <td>54.348499</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>image-asset/taken/IMG_8073.JPG</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>98.892235</td>\n",
       "      <td>HEAD_COVER</td>\n",
       "      <td>61.682014</td>\n",
       "      <td>99.991692</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>image-asset/taken/IMG_8074.JPG</td>\n",
       "      <td>FACE</td>\n",
       "      <td>99.362358</td>\n",
       "      <td>FACE_COVER</td>\n",
       "      <td>91.241142</td>\n",
       "      <td>53.143822</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>image-asset/taken/IMG_8074.JPG</td>\n",
       "      <td>HEAD</td>\n",
       "      <td>99.994049</td>\n",
       "      <td>HEAD_COVER</td>\n",
       "      <td>68.980629</td>\n",
       "      <td>99.348442</td>\n",
       "      <td>0.104634</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 img bodyPartName  bodyPartConf     eq_type  \\\n",
       "0    image-asset/1684177591-huge.jpg         FACE     99.458809  FACE_COVER   \n",
       "1    image-asset/1684177591-huge.jpg         HEAD     99.969254  HEAD_COVER   \n",
       "2    image-asset/1684177591-huge.jpg         FACE     96.018814  FACE_COVER   \n",
       "3    image-asset/1684177591-huge.jpg         HEAD     99.608627  HEAD_COVER   \n",
       "4    image-asset/1684177591-huge.jpg         FACE     94.266830  FACE_COVER   \n",
       "..                               ...          ...           ...         ...   \n",
       "120   image-asset/taken/IMG_8072.JPG         FACE     99.981300  FACE_COVER   \n",
       "121   image-asset/taken/IMG_8073.JPG         HEAD     92.567757  HEAD_COVER   \n",
       "122   image-asset/taken/IMG_8073.JPG         HEAD     98.892235  HEAD_COVER   \n",
       "123   image-asset/taken/IMG_8074.JPG         FACE     99.362358  FACE_COVER   \n",
       "124   image-asset/taken/IMG_8074.JPG         HEAD     99.994049  HEAD_COVER   \n",
       "\n",
       "       eq_conf  eqCover_conf    eq_box eqCover_bool  \n",
       "0    99.934128     90.723564  0.019554         True  \n",
       "1    68.631821     95.665405  0.039268         True  \n",
       "2    99.720436     89.325356  0.009923         True  \n",
       "3    95.798180     98.066414  0.051126         True  \n",
       "4    99.801407     96.197754  0.010404         True  \n",
       "..         ...           ...       ...          ...  \n",
       "120  95.747658     99.999992  0.012923        False  \n",
       "121  54.348499    100.000000  0.012487        False  \n",
       "122  61.682014     99.991692  0.001323         True  \n",
       "123  91.241142     53.143822  0.013208         True  \n",
       "124  68.980629     99.348442  0.104634         True  \n",
       "\n",
       "[125 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ee668",
   "metadata": {},
   "source": [
    "Each detection of a `bodyPart` and its results are stored as one row of a dataframe.\\\n",
    "Now we will save this dataframe as `detect_ppe_output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db1eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"detect_ppe_output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
